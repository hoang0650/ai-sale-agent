import os
import torch
from accelerate import Accelerator
from f5_tts.model import DiT, CFM
from f5_tts.train import Trainer
from dotenv import load_dotenv

load_dotenv()

# C·∫§U H√åNH C·ª®NG (S·ª≠a tr·ª±c ti·∫øp ·ªü ƒë√¢y cho nhanh)
DATASET_NAME = "phil_voice_studio"
OUTPUT_DIR = "outputs/F5-TTS-Phil"
HF_REPO = "phil-ai/Phil-F5-TTS"

def main():
    print(">>> üéôÔ∏è STARTING F5-TTS TRAINING (CLONE YOUR VOICE)...")
    accelerator = Accelerator()
    device = accelerator.device

    # 1. ƒê·ªãnh nghƒ©a Model (Flow Matching Transformer)
    model = DiT(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4).to(device)
    cfm = CFM(transformer=model, sigma_min=0.0, sigma_max=1.0, ode_method='euler').to(device)

    # 2. Dataset Path (Y√™u c·∫ßu c·∫•u tr√∫c: wavs/ v√† metadata.csv)
    dataset_path = os.path.join("data/processed", DATASET_NAME)
    
    # 3. Trainer
    trainer = Trainer(
        cfm,
        args={
            "num_warmup_updates": 200,
            "save_per_updates": 500,
            "checkpoint_path": OUTPUT_DIR,
            "batch_size": 4,  # H200 c√≥ th·ªÉ tƒÉng l√™n 8 ho·∫∑c 16
            "learning_rate": 1e-4,
            "accumulate_grad_batches": 4,
            "epochs": 50 # Train s√¢u ƒë·ªÉ gi·ªçng m∆∞·ª£t
        },
        dataset_path=dataset_path,
    )

    trainer.train()
    print(f">>> ‚úÖ Train xong! Checkpoint l∆∞u t·∫°i {OUTPUT_DIR}")
    # L∆∞u √Ω: F5-TTS hi·ªán t·∫°i upload th·ªß c√¥ng file .pt l√™n HF l√† t·ªët nh·∫•t

if __name__ == "__main__":
    main()