# ðŸ­ Phil AI Training Factory

> **"XÆ°á»Ÿng Ä‘Ãºc" TrÃ­ tuá»‡ nhÃ¢n táº¡o cho Phil - Thá»±c thá»ƒ sá»‘ Viá»‡t Nam (Vietnam's Sovereign Digital Human).**
> Dá»± Ã¡n nÃ y chuyÃªn biá»‡t hÃ³a Ä‘á»ƒ Fine-tune cÃ¡c mÃ´ hÃ¬nh SOTA (State-of-the-Art) háº¡ng náº·ng trÃªn pháº§n cá»©ng **NVIDIA H200 SXM (141GB VRAM)**.

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![Hardware](https://img.shields.io/badge/Hardware-H200_SXM-green.svg)
![Framework](https://img.shields.io/badge/Framework-Unsloth%20%7C%20LLaMA--Factory-red)
![Status](https://img.shields.io/badge/Status-Operational-brightgreen)

---

## ðŸ§  Kiáº¿n TrÃºc "Tá»© Trá»¥" (The Big Four)

Há»‡ thá»‘ng nÃ y khÃ´ng táº¡o ra má»™t chatbot, mÃ  táº¡o ra 4 thÃ nh pháº§n cáº¥u thÃ nh má»™t con ngÆ°á»i ká»¹ thuáº­t sá»‘:

| ThÃ nh pháº§n | Vai trÃ² | Model Gá»‘c (Base) | Ká»¹ thuáº­t Train | Dataset ChÃ­nh |
| :--- | :--- | :--- | :--- | :--- |
| **1. Brain** | TÆ° duy, Code, Logic | `DeepSeek-R1-Distill-Llama-70B` | QLoRA 4-bit (Unsloth) | Glaive + Evol + **Vietnamese Translated** |
| **2. Eyes** | NhÃ¬n, OCR, UI/UX | `OpenGVLab/InternVL2-76B` | QLoRA 4-bit (LLaMA-Factory) | OCR-VQA + Tech Screenshots |
| **3. Ears** | Nghe thuáº­t ngá»¯ IT | `OpenAI/Whisper-Large-v3` | LoRA Adapter | Youtube Tech Talks (Vietnamese) |
| **4. Mouth** | Giá»ng nÃ³i Ä‘á»‹nh danh | `F5-TTS (E2-TTS)` | Flow Matching | **Phil Studio Voice** (Custom) |

---

## ðŸ› ï¸ YÃªu Cáº§u Há»‡ Thá»‘ng

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a cho **Runpod H200 Pod**. KhÃ´ng cháº¡y Ä‘Æ°á»£c trÃªn GPU dÃ¢n dá»¥ng (RTX 4090) hoáº·c A100 80GB Ä‘Æ¡n láº» (Ä‘á»‘i vá»›i Vision & Brain training).

* **GPU:** 1x NVIDIA H200 SXM (141GB VRAM).
* **Disk:** Tá»‘i thiá»ƒu 200GB Container Disk / Volume.
* **RAM:** 128GB+.
* **Internet:** Runpod Datacenter Speed (Download Dataset ~10Gbps).

---

## ðŸ“‚ Cáº¥u TrÃºc Dá»± Ãn

```text
phil-training-factory/
â”œâ”€â”€ configs/                   # Cáº¥u hÃ¬nh Hyperparameters (YAML)
â”‚   â”œâ”€â”€ deepseek_70b.yaml      # Cáº¥u hÃ¬nh Brain
â”‚   â”œâ”€â”€ whisper_large.yaml     # Cáº¥u hÃ¬nh Ears
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/                      # Kho dá»¯ liá»‡u
â”‚   â”œâ”€â”€ raw/                   # Dá»¯ liá»‡u thÃ´
â”‚   â””â”€â”€ processed/             # Dá»¯ liá»‡u sáº¡ch (JSONL, WAV)
â”œâ”€â”€ scripts/                   # Shell scripts Ä‘iá»u khiá»ƒn
â”‚   â”œâ”€â”€ run_internvl2.sh       # Script riÃªng cho Vision
â”‚   â””â”€â”€ run_all.sh             # Script "One-Click" cháº¡y táº¥t cáº£
â”œâ”€â”€ src/                       # MÃ£ nguá»“n Python
â”‚   â”œâ”€â”€ data_processing/       # Module dá»‹ch thuáº­t & xá»­ lÃ½ Audio
â”‚   â””â”€â”€ training/              # Module train Core (Unsloth & F5-TTS)
â””â”€â”€ requirements.txt           # Dependencies
```

---

## ðŸš€ HÆ°á»›ng Dáº«n Váº­n HÃ nh (Step-by-Step)

**BÆ°á»›c 1: Khá»Ÿi táº¡o MÃ´i trÆ°á»ng**
Káº¿t ná»‘i SSH vÃ o Runpod vÃ  cháº¡y:
```bash
# 1. CÃ i Ä‘áº·t thÆ° viá»‡n
pip install -r requirements.txt

# 2. Cáº¥u hÃ¬nh biáº¿n mÃ´i trÆ°á»ng
# Táº¡o file .env vÃ  Ä‘iá»n Token HF cá»§a báº¡n vÃ o
echo "HF_TOKEN=hf_write_token_here" > .env
```
**BÆ°á»›c 2: Chuáº©n bá»‹ "NguyÃªn liá»‡u" (Data Processing)**
Giai Ä‘oáº¡n nÃ y dÃ¹ng vinai/PhoGPT-4B Ä‘á»ƒ Viá»‡t hÃ³a cÃ¡c bá»™ dataset Code cháº¥t lÆ°á»£ng cao.
```bash
python3 src/data_processing/translator_ultimate.py
```
Output: `data/processed/combined_vietnamese_data.jsonl`

**BÆ°á»›c 3: Training**
Báº¡n cÃ³ thá»ƒ cháº¡y tá»«ng module hoáº·c cháº¡y táº¥t cáº£.

**CÃ¡ch 1: Cháº¡y tá»± Ä‘á»™ng (KhuyÃªn dÃ¹ng)
```bash
chmod +x scripts/*.sh
./scripts/run_all.sh
```
LÆ°u Ã½: QuÃ¡ trÃ¬nh nÃ y máº¥t khoáº£ng 5-8 tiáº¿ng trÃªn H200.

**CÃ¡ch 2: Cháº¡y thá»§ cÃ´ng tá»«ng pháº§n**
1. **Train Brain (DeepSeek 70B):**
```bash
python3 src/training/train_generic.py --config configs/deepseek_70b.yaml
```
2. **Train Eyes (InternVL2 76B):**
```bash
./scripts/run_internvl2.sh
```
3. **Train Ears (Whisper):**
```bash
python3 src/training/train_generic.py --config configs/whisper_large.yaml
```
4. **Train Mouth (F5-TTS):**
YÃªu cáº§u: ÄÃ£ bá» file giá»ng máº«u vÃ o `data/processed/phil_voice_studio/`
```bash
python3 src/training/train_f5_tts.py
```
---

## ðŸ“¦ Output Artifacts (Sáº£n pháº©m Ä‘áº§u ra)
Sau khi train xong, cÃ¡c model sáº½ Ä‘Æ°á»£c tá»± Ä‘á»™ng upload lÃªn HuggingFace cá»§a báº¡n vá»›i tÃªn:
* phil-ai/Phil-70B-Coder-N1 (Brain)
* phil-ai/Phil-InternVL2-76B-N1 (Vision)
* phil-ai/Phil-Ear-N1 (STT)
* phil-ai/Phil-F5-TTS (TTS Checkpoint)

---

## ðŸ”Œ Triá»ƒn khai Inference (Phil-CLI)
Äá»ƒ sá»­ dá»¥ng cÃ¡c model nÃ y, hÃ£y chuyá»ƒn sang project phil-cli vÃ  sá»­ dá»¥ng cáº¥u hÃ¬nh Docker Compose sau trÃªn mÃ¡y chá»§ Inference (YÃªu cáº§u VRAM > 110GB):
```yaml
# TrÃ­ch Ä‘oáº¡n docker-compose.yml
services:
  ai-brain:
    image: vllm/vllm-openai
    command: --model phil-ai/Phil-70B-Coder-N1 --quantization awq ...
  
  ai-vision:
    image: openmmlab/lmdeploy
    command: lmdeploy serve api_server phil-ai/Phil-InternVL2-76B-v1 ...
```